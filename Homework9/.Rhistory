pch = 16,
main = "Predicted vs Actual",
xlab = "Actual",
ylab = "Predicted",
col = "blue"
)
abline(0, 1, col = "orange")
n
beta_0  = 1
beta_1  = -1
beta_2  = 2
beta_3  = -2
beta_4  = 1
beta_5  = 1
beta_6  = 0
beta_7  = 0
beta_8  = 0
beta_9  = 0
beta_10 = 0
sigma = 2
not_sig  = c("x_6", "x_7", "x_8", "x_9", "x_10")
signif = c("x_1", "x_2", "x_3", "x_4", "x_5")
set.seed(420)
n = 100
x_1  = runif(n, 0, 10)
x_2  = runif(n, 0, 10)
x_3  = runif(n, 0, 10)
x_4  = runif(n, 0, 10)
x_5  = runif(n, 0, 10)
x_6  = runif(n, 0, 10)
x_7  = runif(n, 0, 10)
x_8  = runif(n, 0, 10)
x_9  = runif(n, 0, 10)
x_10 = runif(n, 0, 10)
sim_data_1 = data.frame(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10,
y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
)
head(sim_data_1)
fit = lm(y ~ x_1 + x_2 + x_6 + x_7, data = sim_data_1)
coef(fit)
# which are false negatives?
!(signif %in% names(coef(fit)))
# which are false positives?
names(coef(fit)) %in% not_sig
false_negpos_df = data.frame(
total_false_negs_aic = rep(0, 300),
total_false_pos_aic = rep(0, 300),
total_false_negs_bic = rep(0, 300),
total_false_pos_bic = rep(0, 300)
)
n
set.seed(19890101)
for (i in 1:300) {
sim_data_1$y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
add_mod = lm(y ~ ., data = sim_data_1)
#backwards AIC
back_aic_mod = step(add_mod, direction = "backward", trace = FALSE)
#backwards BIC
#n_bic = length(add_mod$residuals)
back_bic_mod = step(add_mod, direction = "backward", k = log(n), trace = FALSE)
false_negpos_df$total_false_negs_aic[i] = sum(!(signif %in% names(coef(back_aic_mod))))
false_negpos_df$total_false_pos_aic[i] = sum(names(coef(back_aic_mod)) %in% not_sig)
false_negpos_df$total_false_negs_bic[i] = sum(!(signif %in% names(coef(back_bic_mod))))
false_negpos_df$total_false_pos_bic[i] = sum(names(coef(back_bic_mod)) %in% not_sig)
}
library(knitr)
rate_df = data.frame(
"AIC Error Rate" = c(
"False Negative" = mean(false_negpos_df$total_false_negs_aic),
"False Positive" = mean(false_negpos_df$total_false_pos_aic)
),
"BIC Error Rate" = c(
"False Negative" = mean(false_negpos_df$total_false_negs_bic),
"False Positive" = mean(false_negpos_df$total_false_pos_bic)
)
)
kable(t(rate_df))
set.seed(19890101)
for (i in 1:300) {
sim_data_1$y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
add_mod = lm(y ~ ., data = sim_data_1)
#backwards AIC
back_aic_mod = step(add_mod, direction = "backward", trace = FALSE)
#backwards BIC
#n_bic = length(add_mod$residuals)
back_bic_mod = step(add_mod, direction = "backward", k = log(n), trace = FALSE)
false_negpos_df$total_false_negs_aic[i] = sum(!(signif %in% names(coef(back_aic_mod))))
false_negpos_df$total_false_pos_aic[i] = sum(names(coef(back_aic_mod)) %in% not_sig)
false_negpos_df$total_false_negs_bic[i] = sum(!(signif %in% names(coef(back_bic_mod))))
false_negpos_df$total_false_pos_bic[i] = sum(names(coef(back_bic_mod)) %in% not_sig)
}
set.seed(19890101)
for (i in 1:300) {
sim_data_1$y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
add_mod = lm(y ~ ., data = sim_data_1)
#backwards AIC
back_aic_mod = step(add_mod, direction = "backward", trace = FALSE)
#backwards BIC
n_bic = length(add_mod$residuals)
back_bic_mod = step(add_mod, direction = "backward", k = log(n_bic), trace = FALSE)
false_negpos_df$total_false_negs_aic[i] = sum(!(signif %in% names(coef(back_aic_mod))))
false_negpos_df$total_false_pos_aic[i] = sum(names(coef(back_aic_mod)) %in% not_sig)
false_negpos_df$total_false_negs_bic[i] = sum(!(signif %in% names(coef(back_bic_mod))))
false_negpos_df$total_false_pos_bic[i] = sum(names(coef(back_bic_mod)) %in% not_sig)
}
library(knitr)
rate_df = data.frame(
"AIC Error Rate" = c(
"False Negative" = mean(false_negpos_df$total_false_negs_aic),
"False Positive" = mean(false_negpos_df$total_false_pos_aic)
),
"BIC Error Rate" = c(
"False Negative" = mean(false_negpos_df$total_false_negs_bic),
"False Positive" = mean(false_negpos_df$total_false_pos_bic)
)
)
kable(t(rate_df))
false_negpos_df = data.frame(
total_false_negs_aic = rep(0, 300),
total_false_pos_aic = rep(0, 300),
total_false_negs_bic = rep(0, 300),
total_false_pos_bic = rep(0, 300)
)
set.seed(94)
x_1  = runif(n, 0, 10)
x_2  = runif(n, 0, 10)
x_3  = runif(n, 0, 10)
x_4  = runif(n, 0, 10)
x_5  = runif(n, 0, 10)
x_6  = runif(n, 0, 10)
x_7  = runif(n, 0, 10)
x_8  = x_1 + rnorm(n, 0, 0.1)
x_9  = x_1 + rnorm(n, 0, 0.1)
x_10 = x_2 + rnorm(n, 0, 0.1)
sim_data_2 = data.frame(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8, x_9, x_10,
y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
)
false_negpos_df2 = data.frame(
total_false_negs_aic = rep(0, 300),
total_false_pos_aic = rep(0, 300),
total_false_negs_bic = rep(0, 300),
total_false_pos_bic = rep(0, 300)
)
set.seed(19890101)
for (i in 1:300) {
sim_data_2$y = beta_0 + beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 +
beta_5 * x_5 + rnorm(n, 0 , sigma)
add_mod = lm(y ~ ., data = sim_data_2)
#backwards AIC
back_aic_mod = step(add_mod, direction = "backward", trace = FALSE)
#backwards BIC
back_bic_mod = step(add_mod, direction = "backward", k = log(n), trace = FALSE)
false_negpos_df2$total_false_negs_aic[i] = sum(!(signif %in% names(coef(back_aic_mod))))
false_negpos_df2$total_false_pos_aic[i] = sum(names(coef(back_aic_mod)) %in% not_sig)
false_negpos_df2$total_false_negs_bic[i] = sum(!(signif %in% names(coef(back_bic_mod))))
false_negpos_df2$total_false_pos_bic[i] = sum(names(coef(back_bic_mod)) %in% not_sig)
}
library(knitr)
rate_df = data.frame(
"AIC Error Rate" = c(
"False Negative" = mean(false_negpos_df2$total_false_negs_aic),
"False Positive" = mean(false_negpos_df2$total_false_pos_aic)
),
"BIC Error Rate" = c(
"False Negative" = mean(false_negpos_df2$total_false_negs_bic),
"False Positive" = mean(false_negpos_df2$total_false_pos_bic)
)
)
kable(t(rate_df))
# Chunk 1: setup
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
# Chunk 3
round(cor(longley), 2)
# Chunk 4
library(faraway)
model_full = lm(Employed ~., data = longley )
vif(model_full)
# Chunk 5
sum(vif(model_full) > 5)
# Chunk 6
model_population = lm(Population ~ GNP.deflator + GNP + Unemployed  + Armed.Forces + Year, data = longley )
summary(model_population)$r.squared
# Chunk 7
cor(resid(model_full), resid(model_population))
# Chunk 8
summary(model_full)
model_new = lm(Employed ~ Unemployed + Armed.Forces + Year, data = longley )
vif(model_new)
# Chunk 9
max(vif(model_new))
# Chunk 10
anova(model_full, model_new)
# Chunk 11
plot(fitted(model_new), resid(model_new),
col = "dodgerblue", pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = "darkorange", lwd = 2)
qqnorm(resid(model_new), col = "dodgerblue", pch = 20, cex = 1.5)
qqline(resid(model_new), col = "darkorange", lwd = 2)
# Chunk 12
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
plot(fitted(model), resid(model),
col = pointcol, pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = linecol, lwd = 2)
}
plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
qqline(resid(model), col = linecol, lwd = 2)
}
# Chunk 13
library("lmtest");
bptest(model_new)
# Chunk 14
shapiro.test(resid(model_new))
# Chunk 15
library(ISLR)
data(Credit)
Credit = subset(Credit, select = -c(ID))
# Chunk 16
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 17
#get best model from step search..
start_mod = lm(Balance ~ log(Income) + ., data = Credit)
n = length(start_mod$residuals)
mod_a = step(start_mod, direction = "both", k = log(n), trace = 0)
coef(mod_a)
# Chunk 18
#this model was chosen by looking at #fitted vs residual plot and playing around until I got the results I wanted.
mod_a = lm(Balance ~ log(Income) + Limit + Cards + Age +  Gender ,
data = Credit)
plot(mod_a$fitted.values, mod_a$residuals)
# Chunk 19
get_loocv_rmse(mod_a)
get_adj_r2(mod_a)
get_bp_decision(mod_a, alpha = 0.01)
get_num_params(mod_a)
# Chunk 20
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 21
#find best model from step search for starting point..
start_mod = lm(Balance ~ (.)^2, data = Credit)
n = length(start_mod$residuals)
mod_b = step(start_mod, direction = "backward", k = log(n), trace = 0)
coef(mod_b)
# Chunk 22
#Kept changing model until I got desired results.
mod_b = lm(Balance ~ log(Income) + log(Limit) + Rating + Cards + Age + Student + Income:Rating + Income:Student + Limit:Rating + Limit:Student, data = Credit)
# Chunk 23
get_loocv_rmse(mod_b)
get_adj_r2(mod_b)
get_sw_decision(mod_b, alpha = 0.01)
get_num_params(mod_b)
# Chunk 24
library(caret)
library(ggplot2)
data(Sacramento)
sac_data = Sacramento
sac_data$limits = factor(ifelse(sac_data$city == "SACRAMENTO", "in", "out"))
sac_data = subset(sac_data, select = -c(city, zip))
# Chunk 25
qplot(y = longitude, x = latitude, data = sac_data,
col = limits, main = "Sacramento City Limits ")
# Chunk 26
set.seed(420)
sac_trn_idx  = sample(nrow(sac_data), size = trunc(0.80 * nrow(sac_data)))
sac_trn_data = sac_data[sac_trn_idx, ]
sac_tst_data = sac_data[-sac_trn_idx, ]
# Chunk 27
start_mod = lm(price ~ .^2, data = sac_trn_data)
n = length(resid(start_mod))
mod_a = step(start_mod, direction = "both", k = log(n), trace = 0)
get_loocv_rmse(mod_a)
predicted_value = predict(mod_a, newdata = sac_tst_data)
sumpredminact = mean(abs(predicted_value - sac_tst_data$price) / predicted_value)*100
sumpredminact
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
#get best model from step search..
start_mod = lm(Balance ~ log(Income) + ., data = Credit)
n = length(start_mod$residuals)
mod_a = step(start_mod, direction = "both", k = log(n), trace = 0)
coef(mod_a)
#this model was chosen by looking at #fitted vs residual plot and playing around until I got the results I wanted.
mod_a = lm(Balance ~ log(Income) + Limit + Cards + Age +  Gender ,
data = Credit)
plot(mod_a$fitted.values, mod_a$residuals)
get_loocv_rmse(mod_a)
get_adj_r2(mod_a)
get_bp_decision(mod_a, alpha = 0.01)
get_num_params(mod_a)
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
#get best model from step search..
start_mod = lm(Balance ~ log(Income) + ., data = Credit)
n = length(start_mod$residuals)
mod_a = step(start_mod, direction = "both", k = log(n), trace = 0)
coef(mod_a)
#this model was chosen by looking at #fitted vs residual plot and playing around until I got the results I wanted.
mod_a = lm(Balance ~ log(Income) + (Limit) + (Cards) + Age + Education + Gender + Student, data = Credit)
plot(mod_a$fitted.values, mod_a$residuals)
get_loocv_rmse(mod_a)
get_adj_r2(mod_a)
get_bp_decision(mod_a, alpha = 0.01)
get_num_params(mod_a)
# Chunk 1: setup
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
# Chunk 3
round(cor(longley), 2)
# Chunk 4
library(faraway)
model_full = lm(Employed ~., data = longley )
vif(model_full)
# Chunk 5
sum(vif(model_full) > 5)
# Chunk 6
model_population = lm(Population ~ GNP.deflator + GNP + Unemployed  + Armed.Forces + Year, data = longley )
summary(model_population)$r.squared
# Chunk 7
cor(resid(model_full), resid(model_population))
# Chunk 8
summary(model_full)
model_new = lm(Employed ~ Unemployed + Armed.Forces + Year, data = longley )
vif(model_new)
# Chunk 9
max(vif(model_new))
# Chunk 10
anova(model_full, model_new)
# Chunk 11
plot(fitted(model_new), resid(model_new),
col = "dodgerblue", pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = "darkorange", lwd = 2)
qqnorm(resid(model_new), col = "dodgerblue", pch = 20, cex = 1.5)
qqline(resid(model_new), col = "darkorange", lwd = 2)
# Chunk 12
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
plot(fitted(model), resid(model),
col = pointcol, pch = 20, cex = 1.5,
xlab = "Fitted", ylab = "Residuals")
abline(h = 0, col = linecol, lwd = 2)
}
plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
qqline(resid(model), col = linecol, lwd = 2)
}
# Chunk 13
library("lmtest");
bptest(model_new)
# Chunk 14
shapiro.test(resid(model_new))
# Chunk 15
library(ISLR)
data(Credit)
Credit = subset(Credit, select = -c(ID))
# Chunk 16
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 17
#get best model from step search..
start_mod = lm(Balance ~ log(Income) + ., data = Credit)
n = length(start_mod$residuals)
mod_a = step(start_mod, direction = "both", k = log(n), trace = 0)
coef(mod_a)
# Chunk 18
#this model was chosen by looking at #fitted vs residual plot and playing around until I got the results I wanted.
mod_a = lm(Balance ~ log(Income) + (Limit) + (Cards) + Age + Education + Gender + Student, data = Credit)
plot(mod_a$fitted.values, mod_a$residuals)
# Chunk 19
get_loocv_rmse(mod_a)
get_adj_r2(mod_a)
get_bp_decision(mod_a, alpha = 0.01)
get_num_params(mod_a)
# Chunk 20
library(lmtest)
get_bp_decision = function(model, alpha) {
decide = unname(bptest(model)$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_sw_decision = function(model, alpha) {
decide = unname(shapiro.test(resid(model))$p.value < alpha)
ifelse(decide, "Reject", "Fail to Reject")
}
get_num_params = function(model) {
length(coef(model))
}
get_loocv_rmse = function(model) {
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
get_adj_r2 = function(model) {
summary(model)$adj.r.squared
}
# Chunk 21
#find best model from step search for starting point..
start_mod = lm(Balance ~ (.)^2, data = Credit)
n = length(start_mod$residuals)
mod_b = step(start_mod, direction = "backward", k = log(n), trace = 0)
coef(mod_b)
# Chunk 22
#Kept changing model until I got desired results.
mod_b = lm(Balance ~ log(Income) + log(Limit) + Rating + Cards + Age + Student + Income:Rating + Income:Student + Limit:Rating + Limit:Student, data = Credit)
# Chunk 23
get_loocv_rmse(mod_b)
get_adj_r2(mod_b)
get_sw_decision(mod_b, alpha = 0.01)
get_num_params(mod_b)
# Chunk 24
library(caret)
library(ggplot2)
data(Sacramento)
sac_data = Sacramento
sac_data$limits = factor(ifelse(sac_data$city == "SACRAMENTO", "in", "out"))
sac_data = subset(sac_data, select = -c(city, zip))
# Chunk 25
qplot(y = longitude, x = latitude, data = sac_data,
col = limits, main = "Sacramento City Limits ")
# Chunk 26
set.seed(420)
sac_trn_idx  = sample(nrow(sac_data), size = trunc(0.80 * nrow(sac_data)))
sac_trn_data = sac_data[sac_trn_idx, ]
sac_tst_data = sac_data[-sac_trn_idx, ]
start_mod = lm(price ~ .^2, data = sac_trn_data)
n = length(resid(start_mod))
mod_a = step(start_mod, direction = "both", k = log(n), trace = 0)
get_loocv_rmse(mod_a)
